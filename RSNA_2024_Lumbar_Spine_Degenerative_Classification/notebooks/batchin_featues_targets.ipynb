{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path):\n",
    "    dicom = pydicom.dcmread(image_path)\n",
    "\n",
    "    # Convert the DCM image to a numpy array\n",
    "    image_array = dicom.pixel_array\n",
    "\n",
    "    # Resize the image using OpenCV\n",
    "    resized_image = cv2.resize(image_array, (224, 224))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142859125 (8064, 224)\n",
      "2073726394 (10304, 224)\n",
      "2399638375 (4256, 224)\n",
      "3491739931 (4256, 224)\n",
      "1224932122 (10080, 224)\n",
      "2231042680 (4032, 224)\n",
      "3543553307 (4032, 224)\n",
      "1212326388 (3360, 224)\n",
      "1638921810 (3360, 224)\n",
      "3800798510 (6048, 224)\n",
      "403244853 (6272, 224)\n",
      "1539051863 (3808, 224)\n",
      "2500166693 (6048, 224)\n",
      "2677627096 (3808, 224)\n",
      "3687121182 (12992, 224)\n",
      "3753885158 (4032, 224)\n",
      "434280813 (4032, 224)\n",
      "1679014482 (10080, 224)\n",
      "226564374 (3808, 224)\n",
      "2528347280 (3808, 224)\n",
      "307069509 (5600, 224)\n",
      "1152175603 (5152, 224)\n",
      "1676821058 (5152, 224)\n",
      "2261718442 (6720, 224)\n",
      "231278500 (8960, 224)\n",
      "1379151387 (3360, 224)\n",
      "1847558962 (4928, 224)\n",
      "758801267 (3360, 224)\n",
      "1054713880 (3360, 224)\n",
      "2448190387 (9632, 224)\n",
      "702807833 (3360, 224)\n",
      "3201256954 (12096, 224)\n",
      "3486248476 (3808, 224)\n",
      "3666319702 (3808, 224)\n",
      "132939515 (3808, 224)\n",
      "1951927562 (5152, 224)\n",
      "3219733239 (3808, 224)\n",
      "1570286759 (3360, 224)\n",
      "2406919186 (4704, 224)\n",
      "481125819 (3360, 224)\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the main directory containing patient folders\n",
    "main_directory = './small_train_images'\n",
    "\n",
    "# Dictionary to store image data\n",
    "image_data = {}\n",
    "\n",
    "# Iterate over study_id folders\n",
    "for study_id in os.listdir(main_directory):\n",
    "    study_id_dir = os.listdir(f'./small_train_images/{study_id}')\n",
    "    \n",
    "    # Iterate over series folders for each patient\n",
    "    for series_id in study_id_dir:\n",
    "        series_id_dir = os.listdir(f'./small_train_images/{study_id}/{series_id}')\n",
    "        # Initialize list to store image arrays for the series\n",
    "        image_arrays = []\n",
    "        \n",
    "        # Iterate over DICOM files in the series folder\n",
    "        for instance in series_id_dir:\n",
    "            image_path = f'./small_train_images/{study_id}/{series_id}/{instance}'\n",
    "            resized_image = resize_image(image_path)\n",
    "\n",
    "            # Append resized_image array to the list\n",
    "            image_arrays.append(resized_image)\n",
    "        \n",
    "        # Vertically stack DCM images\n",
    "        stacked_images = np.vstack(image_arrays)\n",
    "        # Store stacked images as a NumPy array\n",
    "        np_array = np.array(stacked_images)\n",
    "        print(series_id, np_array.shape)\n",
    "\n",
    "        # Store image arrays in the dictionary with (study_id, series_id) tuple as key\n",
    "        image_data[(study_id, series_id)] = np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (3360, 224)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "example_study_id = '4003253'\n",
    "example_series_id = '702807833'\n",
    "if (example_study_id, example_series_id) in image_data:\n",
    "    image = image_data[(example_study_id, example_series_id)]\n",
    "    print(f\"Image shape:\", image.shape)\n",
    "else:\n",
    "    print(\"No images found for the specified (study_id, series_id) tuple.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10728036', '142859125') (12992, 224)\n",
      "('10728036', '2073726394') (12992, 224)\n",
      "('10728036', '2399638375') (12992, 224)\n",
      "('10728036', '3491739931') (12992, 224)\n",
      "('11340341', '1224932122') (12992, 224)\n",
      "('11340341', '2231042680') (12992, 224)\n",
      "('11340341', '3543553307') (12992, 224)\n",
      "('11943292', '1212326388') (12992, 224)\n",
      "('11943292', '1638921810') (12992, 224)\n",
      "('11943292', '3800798510') (12992, 224)\n",
      "('11943292', '403244853') (12992, 224)\n",
      "('13317052', '1539051863') (12992, 224)\n",
      "('13317052', '2500166693') (12992, 224)\n",
      "('13317052', '2677627096') (12992, 224)\n",
      "('22191399', '3687121182') (12992, 224)\n",
      "('22191399', '3753885158') (12992, 224)\n",
      "('22191399', '434280813') (12992, 224)\n",
      "('26342422', '1679014482') (12992, 224)\n",
      "('26342422', '226564374') (12992, 224)\n",
      "('26342422', '2528347280') (12992, 224)\n",
      "('26342422', '307069509') (12992, 224)\n",
      "('29931867', '1152175603') (12992, 224)\n",
      "('29931867', '1676821058') (12992, 224)\n",
      "('29931867', '2261718442') (12992, 224)\n",
      "('29931867', '231278500') (12992, 224)\n",
      "('33736057', '1379151387') (12992, 224)\n",
      "('33736057', '1847558962') (12992, 224)\n",
      "('33736057', '758801267') (12992, 224)\n",
      "('4003253', '1054713880') (12992, 224)\n",
      "('4003253', '2448190387') (12992, 224)\n",
      "('4003253', '702807833') (12992, 224)\n",
      "('4646740', '3201256954') (12992, 224)\n",
      "('4646740', '3486248476') (12992, 224)\n",
      "('4646740', '3666319702') (12992, 224)\n",
      "('7143189', '132939515') (12992, 224)\n",
      "('7143189', '1951927562') (12992, 224)\n",
      "('7143189', '3219733239') (12992, 224)\n",
      "('8785691', '1570286759') (12992, 224)\n",
      "('8785691', '2406919186') (12992, 224)\n",
      "('8785691', '481125819') (12992, 224)\n"
     ]
    }
   ],
   "source": [
    "# Pad arrays\n",
    "\n",
    "# Find the maximum shape among all numpy arrays\n",
    "max_shape = max([np_array.shape for np_array in image_data.values()], key=lambda x: x[0])\n",
    "\n",
    "for key in image_data:\n",
    "    np_array = image_data[key]\n",
    "    padding = max_shape[0] - np_array.shape[0]\n",
    "    if padding > 0:\n",
    "        padding_shape = ((0, padding), (0, 0))\n",
    "        padded_np_array = np.pad(np_array, padding_shape, mode='constant', constant_values=0) # 0 is black (If I'm not mistaken)\n",
    "        image_data[key] = padded_np_array\n",
    "\n",
    "# Print the shapes of padded numpy arrays\n",
    "for key in image_data:\n",
    "    print(key, image_data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked arrays for key 10728036: torch.Size([4, 12992, 224])\n",
      "Stacked arrays for key 11340341: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 11943292: torch.Size([4, 12992, 224])\n",
      "Stacked arrays for key 13317052: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 22191399: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 26342422: torch.Size([4, 12992, 224])\n",
      "Stacked arrays for key 29931867: torch.Size([4, 12992, 224])\n",
      "Stacked arrays for key 33736057: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 4003253: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 4646740: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 7143189: torch.Size([3, 12992, 224])\n",
      "Stacked arrays for key 8785691: torch.Size([3, 12992, 224])\n"
     ]
    }
   ],
   "source": [
    "# Make 3D arrays\n",
    "\n",
    "# Group arrays by the first tuple values\n",
    "grouped_arrays = {}\n",
    "for key, value in image_data.items():\n",
    "    if key[0] not in grouped_arrays:\n",
    "        grouped_arrays[key[0]] = [value]\n",
    "    else:\n",
    "        grouped_arrays[key[0]].append(value)\n",
    "\n",
    "# Stack arrays with the same first tuple values into a 3D array\n",
    "stacked_arrays = {}\n",
    "for key, values in grouped_arrays.items():\n",
    "    stacked_arrays[key] = np.stack(values, axis=0)\n",
    "\n",
    "stacked_tensors = {}\n",
    "for key, value in stacked_arrays.items():\n",
    "    stacked_tensors[key] = torch.from_numpy(value)\n",
    "\n",
    "# Check the stacked arrays\n",
    "for key, value in stacked_tensors.items():\n",
    "    print(f\"Stacked arrays for key {key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum shape\n",
    "max_shape = tuple(max(arr.shape[i] for arr in stacked_tensors.values()) for i in range(3))\n",
    "\n",
    "# Pad each tensor to the maximum shape\n",
    "for key, tensor in stacked_tensors.items():\n",
    "    pad_shape = [max_shape[i] - tensor.shape[i] for i in range(3)]\n",
    "    stacked_tensors[key] = F.pad(tensor, (0, pad_shape[2], 0, pad_shape[1], 0, pad_shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10728036, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 11340341, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 11943292, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 13317052, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 22191399, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 26342422, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 29931867, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 33736057, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 4003253, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 4646740, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 7143189, New Shape: torch.Size([4, 12992, 224])\n",
      "Key: 8785691, New Shape: torch.Size([4, 12992, 224])\n"
     ]
    }
   ],
   "source": [
    "# Print the new shapes\n",
    "for key, arr in stacked_tensors.items():\n",
    "    print(f\"Key: {key}, New Shape: {arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add targets\n",
    "targets_df = pd.read_csv('./train.csv')\n",
    "\n",
    "mapping = {\n",
    "    'normal/mild': 1,\n",
    "    'moderate': 2,\n",
    "    'severe': 3\n",
    "}\n",
    "def standardize_and_map(column, mapping):\n",
    "    return column.str.lower().str.strip().map(mapping)\n",
    "\n",
    "# List of columns to apply the transformation\n",
    "columns_to_transform = ['spinal_canal_stenosis_l1_l2',\n",
    "       'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4',\n",
    "       'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1',\n",
    "       'left_neural_foraminal_narrowing_l1_l2',\n",
    "       'left_neural_foraminal_narrowing_l2_l3',\n",
    "       'left_neural_foraminal_narrowing_l3_l4',\n",
    "       'left_neural_foraminal_narrowing_l4_l5',\n",
    "       'left_neural_foraminal_narrowing_l5_s1',\n",
    "       'right_neural_foraminal_narrowing_l1_l2',\n",
    "       'right_neural_foraminal_narrowing_l2_l3',\n",
    "       'right_neural_foraminal_narrowing_l3_l4',\n",
    "       'right_neural_foraminal_narrowing_l4_l5',\n",
    "       'right_neural_foraminal_narrowing_l5_s1',\n",
    "       'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3',\n",
    "       'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5',\n",
    "       'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2',\n",
    "       'right_subarticular_stenosis_l2_l3',\n",
    "       'right_subarticular_stenosis_l3_l4',\n",
    "       'right_subarticular_stenosis_l4_l5',\n",
    "       'right_subarticular_stenosis_l5_s1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the specified columns\n",
    "for column in columns_to_transform:\n",
    "    targets_df[column] = standardize_and_map(targets_df[column], mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3  \\\n",
       "0   4003253                          1.0                          1.0   \n",
       "\n",
       "   spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5  \\\n",
       "0                          1.0                          1.0   \n",
       "\n",
       "   spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                          1.0                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l4_l5  ...  \\\n",
       "0                                    2.0  ...   \n",
       "\n",
       "   left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3  \\\n",
       "0                               1.0                               1.0   \n",
       "\n",
       "   left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5  \\\n",
       "0                               1.0                               2.0   \n",
       "\n",
       "   left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2  \\\n",
       "0                               1.0                                1.0   \n",
       "\n",
       "   right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4  \\\n",
       "0                                1.0                                1.0   \n",
       "\n",
       "   right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n",
       "0                                1.0                                1.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = targets_df[targets_df['study_id'] == 4003253]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store targets in a dict as numpy arrays and rashape them\n",
    "\n",
    "# targets_dict = {}\n",
    "\n",
    "# for key, arr in stacked_tensors.items():\n",
    "#     target = targets_df[targets_df['study_id'] == int(key)]\n",
    "#     target_study_id = target.iloc[:, :1]\n",
    "#     target_values_int = np.array(target.iloc[:, 1:]).flatten().astype(int) - 1\n",
    "#     # target_values = target.iloc[:, 1:]\n",
    "\n",
    "#     # Convert the target array to one-hot encoding with three classes\n",
    "#     num_classes = 3\n",
    "#     # one_hot_targets = np.eye(num_classes)[np.array(target_values).flatten() - 1]  # Subtracting 1 to make classes start from 0\n",
    "#     one_hot_targets = np.eye(num_classes)[target_values_int]\n",
    "\n",
    "#     # Reshape the one-hot encoded target array to match the desired output shape (25, 3)\n",
    "#     reshaped_targets = one_hot_targets.reshape(-1, num_classes)\n",
    "\n",
    "#     targets_dict[target_study_id.iloc[0, 0]] = reshaped_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store targets in a dict as torch tensors and rashape them\n",
    "\n",
    "targets_tensors = {}\n",
    "\n",
    "for key, arr in stacked_tensors.items():\n",
    "    target = targets_df[targets_df['study_id'] == int(key)]\n",
    "    target_study_id = target.iloc[:, :1]\n",
    "    target_values_int = np.array(target.iloc[:, 1:]).flatten().astype(int) - 1\n",
    "\n",
    "    # Convert the target array to one-hot encoding with three classes\n",
    "    num_classes = 3\n",
    "    one_hot_targets = np.eye(num_classes)[target_values_int]\n",
    "\n",
    "    # Reshape the one-hot encoded target array to match the desired output shape (25, 3)\n",
    "    reshaped_targets = one_hot_targets.reshape(-1, num_classes)\n",
    "\n",
    "    # Convert the numpy array to a torch tensor\n",
    "    tensor_targets = torch.from_numpy(reshaped_targets)\n",
    "\n",
    "    targets_tensors[target_study_id.iloc[0, 0]] = tensor_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10728036, New Shape: torch.Size([25, 3])\n",
      "Key: 11340341, New Shape: torch.Size([25, 3])\n",
      "Key: 11943292, New Shape: torch.Size([25, 3])\n",
      "Key: 13317052, New Shape: torch.Size([25, 3])\n",
      "Key: 22191399, New Shape: torch.Size([25, 3])\n",
      "Key: 26342422, New Shape: torch.Size([25, 3])\n",
      "Key: 29931867, New Shape: torch.Size([25, 3])\n",
      "Key: 33736057, New Shape: torch.Size([25, 3])\n",
      "Key: 4003253, New Shape: torch.Size([25, 3])\n",
      "Key: 4646740, New Shape: torch.Size([25, 3])\n",
      "Key: 7143189, New Shape: torch.Size([25, 3])\n",
      "Key: 8785691, New Shape: torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "# Print the new shapes\n",
    "for key, arr in targets_tensors.items():\n",
    "    print(f\"Key: {key}, New Shape: {arr.shape}\")\n",
    "    # if key == 4003253:\n",
    "    #     print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10728036, New Shape: torch.Size([4, 12992, 224]) | Key: 10728036, New Shape: torch.Size([25, 3])\n",
      "Key: 11340341, New Shape: torch.Size([4, 12992, 224]) | Key: 11340341, New Shape: torch.Size([25, 3])\n",
      "Key: 11943292, New Shape: torch.Size([4, 12992, 224]) | Key: 11943292, New Shape: torch.Size([25, 3])\n",
      "Key: 13317052, New Shape: torch.Size([4, 12992, 224]) | Key: 13317052, New Shape: torch.Size([25, 3])\n",
      "Key: 22191399, New Shape: torch.Size([4, 12992, 224]) | Key: 22191399, New Shape: torch.Size([25, 3])\n",
      "Key: 26342422, New Shape: torch.Size([4, 12992, 224]) | Key: 26342422, New Shape: torch.Size([25, 3])\n",
      "Key: 29931867, New Shape: torch.Size([4, 12992, 224]) | Key: 29931867, New Shape: torch.Size([25, 3])\n",
      "Key: 33736057, New Shape: torch.Size([4, 12992, 224]) | Key: 33736057, New Shape: torch.Size([25, 3])\n",
      "Key: 4003253, New Shape: torch.Size([4, 12992, 224]) | Key: 4003253, New Shape: torch.Size([25, 3])\n",
      "Key: 4646740, New Shape: torch.Size([4, 12992, 224]) | Key: 4646740, New Shape: torch.Size([25, 3])\n",
      "Key: 7143189, New Shape: torch.Size([4, 12992, 224]) | Key: 7143189, New Shape: torch.Size([25, 3])\n",
      "Key: 8785691, New Shape: torch.Size([4, 12992, 224]) | Key: 8785691, New Shape: torch.Size([25, 3])\n"
     ]
    }
   ],
   "source": [
    "for ((key, feature),(key2, targets)) in zip(stacked_tensors.items(), targets_tensors.items()):\n",
    "    print(f\"Key: {key}, New Shape: {feature.shape} | Key: {key2}, New Shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4, 12992, 224]) torch.Size([12, 25, 3])\n"
     ]
    }
   ],
   "source": [
    "# Convert all tensors to float32\n",
    "feature_tensorstest = [tensor.float() for tensor in stacked_tensors.values()]\n",
    "target_tensorstest = [tensor.float() for tensor in targets_tensors.values()]\n",
    "\n",
    "# Stack the tensors\n",
    "X_train = torch.stack(feature_tensorstest)\n",
    "y_train = torch.stack(target_tensorstest)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch DataLoader\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tensor 1 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n",
      "train tensor 2 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n",
      "train tensor 3 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n",
      "train tensor 4 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n",
      "train tensor 5 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n",
      "train tensor 6 | torch.Size([2, 4, 12992, 224]) | torch.Size([2, 25, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check DataLoader batches\n",
    "for i, train_batch in enumerate(train_loader):\n",
    "    x_train_batch, y_train_batch = train_batch\n",
    "    print(f'train tensor {i+1}', '|', x_train_batch.shape, '|', y_train_batch.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
