{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add targets\n",
    "targets_df = pd.read_csv('./train.csv')\n",
    "\n",
    "mapping = {\n",
    "    'normal/mild': 1,\n",
    "    'moderate': 2,\n",
    "    'severe': 3\n",
    "}\n",
    "def standardize_and_map(column, mapping):\n",
    "    return column.str.lower().str.strip().map(mapping)\n",
    "\n",
    "# List of columns to apply the transformation\n",
    "columns_to_transform = ['spinal_canal_stenosis_l1_l2',\n",
    "       'spinal_canal_stenosis_l2_l3', 'spinal_canal_stenosis_l3_l4',\n",
    "       'spinal_canal_stenosis_l4_l5', 'spinal_canal_stenosis_l5_s1',\n",
    "       'left_neural_foraminal_narrowing_l1_l2',\n",
    "       'left_neural_foraminal_narrowing_l2_l3',\n",
    "       'left_neural_foraminal_narrowing_l3_l4',\n",
    "       'left_neural_foraminal_narrowing_l4_l5',\n",
    "       'left_neural_foraminal_narrowing_l5_s1',\n",
    "       'right_neural_foraminal_narrowing_l1_l2',\n",
    "       'right_neural_foraminal_narrowing_l2_l3',\n",
    "       'right_neural_foraminal_narrowing_l3_l4',\n",
    "       'right_neural_foraminal_narrowing_l4_l5',\n",
    "       'right_neural_foraminal_narrowing_l5_s1',\n",
    "       'left_subarticular_stenosis_l1_l2', 'left_subarticular_stenosis_l2_l3',\n",
    "       'left_subarticular_stenosis_l3_l4', 'left_subarticular_stenosis_l4_l5',\n",
    "       'left_subarticular_stenosis_l5_s1', 'right_subarticular_stenosis_l1_l2',\n",
    "       'right_subarticular_stenosis_l2_l3',\n",
    "       'right_subarticular_stenosis_l3_l4',\n",
    "       'right_subarticular_stenosis_l4_l5',\n",
    "       'right_subarticular_stenosis_l5_s1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the specified columns\n",
    "for column in columns_to_transform:\n",
    "    targets_df[column] = standardize_and_map(targets_df[column], mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id  spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3  \\\n",
       "4  10728036                          1.0                          1.0   \n",
       "\n",
       "   spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5  \\\n",
       "4                          1.0                          1.0   \n",
       "\n",
       "   spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2  \\\n",
       "4                          1.0                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l2_l3  \\\n",
       "4                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l3_l4  \\\n",
       "4                                    1.0   \n",
       "\n",
       "   left_neural_foraminal_narrowing_l4_l5  ...  \\\n",
       "4                                    1.0  ...   \n",
       "\n",
       "   left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3  \\\n",
       "4                               1.0                               1.0   \n",
       "\n",
       "   left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5  \\\n",
       "4                               1.0                               1.0   \n",
       "\n",
       "   left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2  \\\n",
       "4                               1.0                                1.0   \n",
       "\n",
       "   right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4  \\\n",
       "4                                1.0                                1.0   \n",
       "\n",
       "   right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n",
       "4                                2.0                                1.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = targets_df[targets_df['study_id'] == 10728036]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_tensors = {'10728036': 1, '11340341': 2, '11943292': 3, '13317052': 4, '22191399': 5, '26342422': 6, '29931867': 7, '33736057': 8, '4003253': 9, '4646740': 10, '7143189': 11, '8785691': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store targets in a dict as torch tensors and rashape them\n",
    "\n",
    "targets_tensors = {}\n",
    "\n",
    "for key, arr in stacked_tensors.items():\n",
    "    target = targets_df[targets_df['study_id'] == int(key)]\n",
    "    target_study_id = target.iloc[:, :1]\n",
    "    target_values_int = np.array(target.iloc[:, 1:]).flatten().astype(int) - 1\n",
    "\n",
    "    # Convert the target array to one-hot encoding with three classes\n",
    "    num_classes = 3\n",
    "    one_hot_targets = np.eye(num_classes)[target_values_int]\n",
    "\n",
    "    # Reshape the one-hot encoded target array to match the desired output shape (25, 3)\n",
    "    reshaped_targets = one_hot_targets.reshape(-1, num_classes)\n",
    "\n",
    "    # Convert the numpy array to a torch tensor\n",
    "    tensor_targets = torch.from_numpy(reshaped_targets)\n",
    "\n",
    "    targets_tensors[target_study_id.iloc[0, 0]] = tensor_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see = targets_tensors[13317052]\n",
    "see.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomCNN, self).__init__()\n",
    "\n",
    "#         # Convolutional and Pooling layers\n",
    "#         self.conv1 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         # Linear layers\n",
    "#         self.fc1 = nn.Linear(32 * 8 * 8, 512)  # Adjust the input features to match the output of your last conv layer\n",
    "#         self.fc2 = nn.Linear(512, 25*3)  # The output should match the flattened target tensor shape\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Define the forward pass\n",
    "#         x = F.relu(self.conv1(x))\n",
    "\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         # ... add more layers as needed ...\n",
    "#         x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layer\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # self.layer1 = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "        #     nn.MaxPool2d(kernel_size=(8, 2), stride=(8, 2)))  # Large pooling to reduce height quickly\n",
    "        # self.layer2 = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "        #     nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2)))  # Smaller pooling\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(8, 2), stride=(8, 2))  # Large pooling to reduce height quickly\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(4, 2), stride=(4, 2))  # Smaller pooling\n",
    "\n",
    "        self.fc1 = nn.Linear(32*406*56, 25*3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        # x = self.fc1(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.reshape(x.shape[0], 25, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 25, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 4, 12992, 224)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = torch.randn(2, 3, 25)\n",
    "# targets = targets.view(2, -1)\n",
    "# x = x.reshape(x.shape[0], 25, 3)\n",
    "targets = targets.reshape(targets.shape[0], -1)\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x6272 and 28x75)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 33\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     35\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\very_big_work\\ML_projects\\RSNA_2024_Lumbar_Spine_Degenerative_Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\very_big_work\\ML_projects\\RSNA_2024_Lumbar_Spine_Degenerative_Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 16\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Additional layers...\u001b[39;00m\n\u001b[0;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Flatten the tensor for the fully connected layer\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32md:\\very_big_work\\ML_projects\\RSNA_2024_Lumbar_Spine_Degenerative_Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\very_big_work\\ML_projects\\RSNA_2024_Lumbar_Spine_Degenerative_Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\very_big_work\\ML_projects\\RSNA_2024_Lumbar_Spine_Degenerative_Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x6272 and 28x75)"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        # Additional layers...\n",
    "        self.fc = nn.Linear(in_features=28 , out_features=75) # Adjust in_features according to previous layer output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        # Additional layers...\n",
    "        x = x.view(x.size(0), -1) # Flatten the tensor for the fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, 25, 3) # Reshape to match the target shape\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNNModel()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss() # Suitable for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example input batch\n",
    "inputs = torch.randn(2, 1, 28, 28) # Example input shape, adjust as necessary\n",
    "targets = torch.randint(0, 2, (2, 25, 3)).float() # Random targets for demonstration\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{5}], Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
